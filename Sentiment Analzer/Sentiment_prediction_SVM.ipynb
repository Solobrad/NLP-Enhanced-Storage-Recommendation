{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Datasets from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16310</th>\n",
       "      <td>I saw this movie in sixth grade around Christm...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>Refreshing `lost' gem! Featuring effective dia...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48601</th>\n",
       "      <td>I love old \"monster movies\" for the pure camp ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48454</th>\n",
       "      <td>This film gets off to a bad start. An incredib...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16928</th>\n",
       "      <td>Meatballs has been a main staple in my family ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19705</th>\n",
       "      <td>I think Dark Angel is great! First season was ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47795</th>\n",
       "      <td>It is hard to judge 'Imaginary Heroes' without...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49953</th>\n",
       "      <td>It's really rare that you get an inside view a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>I purchased a DVD of this film for a dollar at...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44777</th>\n",
       "      <td>Not too many people seem to know about this mo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "16310  I saw this movie in sixth grade around Christm...  positive\n",
       "11301  Refreshing `lost' gem! Featuring effective dia...  positive\n",
       "48601  I love old \"monster movies\" for the pure camp ...  negative\n",
       "48454  This film gets off to a bad start. An incredib...  positive\n",
       "16928  Meatballs has been a main staple in my family ...  positive\n",
       "19705  I think Dark Angel is great! First season was ...  positive\n",
       "47795  It is hard to judge 'Imaginary Heroes' without...  positive\n",
       "49953  It's really rare that you get an inside view a...  positive\n",
       "1442   I purchased a DVD of this film for a dollar at...  negative\n",
       "44777  Not too many people seem to know about this mo...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv('IMDB_Dataset.csv')\n",
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['sentiment'].replace(['positive', 'negative'],['1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46250</th>\n",
       "      <td>Slow, odd film that drags and plods (I mean re...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9219</th>\n",
       "      <td>A young couple Mandy Pullman (Mitch Martin) an...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>I saw this movie a fews years ago and was lite...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47901</th>\n",
       "      <td>I've never seen many online movies in most of ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15437</th>\n",
       "      <td>This is a VERY entertaining movie. A few of th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37808</th>\n",
       "      <td>I think the majority of the people seem not th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>What can you say about the film White Fire. Am...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784</th>\n",
       "      <td>Aunt Cora had always been tactless, and her we...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44297</th>\n",
       "      <td>Ruth Gordon is one of the more sympathetic kil...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5683</th>\n",
       "      <td>I wish that all the mockumentaries and horror ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment label\n",
       "46250  Slow, odd film that drags and plods (I mean re...  negative     0\n",
       "9219   A young couple Mandy Pullman (Mitch Martin) an...  negative     0\n",
       "1111   I saw this movie a fews years ago and was lite...  positive     1\n",
       "47901  I've never seen many online movies in most of ...  positive     1\n",
       "15437  This is a VERY entertaining movie. A few of th...  positive     1\n",
       "37808  I think the majority of the people seem not th...  positive     1\n",
       "400    What can you say about the film White Fire. Am...  positive     1\n",
       "11784  Aunt Cora had always been tactless, and her we...  positive     1\n",
       "44297  Ruth Gordon is one of the more sympathetic kil...  positive     1\n",
       "5683   I wish that all the mockumentaries and horror ...  negative     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    25000\n",
       "0    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('IMDB_Dataset_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing for sentiment analysis\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "class AntonymReplacer(object):\n",
    "    # Class for replacing negations with their antonyms\n",
    "    def replace(self, word, pos=None):\n",
    "        antonyms = set()\n",
    "\n",
    "        for syn in wordnet.synsets(word, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def replace_negations(self, sent):\n",
    "        i, l = 0, len(sent)\n",
    "        words = []\n",
    "\n",
    "        while i < l:\n",
    "            word = sent[i]\n",
    "\n",
    "            if word == 'not' and i+1 < l:\n",
    "                ant = self.replace(sent[i+1])\n",
    "\n",
    "                if ant:\n",
    "                    words.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            words.append(word)\n",
    "            i += 1\n",
    "\n",
    "        return words\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    #1. Generating the list of words in the tweet (hastags and other punctuations removed)\n",
    "    text_blob = TextBlob(text)\n",
    "    text = ' '.join(text_blob.words)\n",
    "    \n",
    "    #2. clean the number \n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    \n",
    "    #3. lower the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #4. conver the emoji to text form\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    #5. remove punctuation \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    \n",
    "    #6. tokenize the text\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    #7. remove empty token\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    \n",
    "    #8. remove non-alphabetical token\n",
    "    text = [t for t in text if t.isalpha()]\n",
    "    \n",
    "    #9. replace the negation token\n",
    "    replacer  = AntonymReplacer()\n",
    "    text = replacer.replace_negations(text)\n",
    "    \n",
    "    #10. remove the stopwords\n",
    "    text = [i for i in text if i not in stopwords]\n",
    "    \n",
    "    #11. stem the text\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    text = [porter_stemmer.stem(w) for w in text]\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So im not a big fan of Boll's work but then again not many are. I enjoyed his movie Postal (maybe im the only one). Boll apparently bought the rights to use Far Cry long ago even before the game itself was even finsished. <br /><br />People who have enjoyed killing mercs and infiltrating secret research labs located on a tropical island should be warned, that this is not Far Cry... This is something Mr Boll have schemed together along with his legion of schmucks.. Feeling loneley on the set Mr Boll invites three of his countrymen to play with. These players go by the names of Til Schweiger, Udo Kier and Ralf Moeller.<br /><br />Three names that actually have made them selfs pretty big in the movie biz. So the tale goes like this, Jack Carver played by Til Schweiger (yes Carver is German all hail the bratwurst eating dudes!!) However I find that Tils acting in this movie is pretty badass.. People have complained about how he's not really staying true to the whole Carver agenda but we only saw carver in a first person perspective so we don't really know what he looked like when he was kicking a**.. <br /><br />However, the storyline in this film is beyond demented. We see the evil mad scientist Dr. Krieger played by Udo Kier, making Genetically-Mutated-soldiers or GMS as they are called. Performing his top-secret research on an island that reminds me of \"SPOILER\" Vancouver for some reason. Thats right no palm trees here. Instead we got some nice rich lumberjack-woods. We haven't even gone FAR before I started to CRY (mehehe) I cannot go on any more.. If you wanna stay true to Bolls shenanigans then go and see this movie you will not be disappointed it delivers the true Boll experience, meaning most of it will suck.<br /><br />There are some things worth mentioning that would imply that Boll did a good work on some areas of the film such as some nice boat and fighting scenes. Until the whole cromed/albino GMS squad enters the scene and everything just makes me laugh.. The movie Far Cry reeks of scheisse (that's poop for you simpletons) from a fa,r if you wanna take a wiff go ahead.. BTW Carver gets a very annoying sidekick who makes you wanna shoot him the first three minutes he's on screen.\n",
      "['im', 'big', 'fan', 'boll', 'work', 'enjoy', 'movi', 'postal', 'mayb', 'im', 'one', 'boll', 'appar', 'bought', 'right', 'use', 'far', 'cri', 'long', 'ago', 'even', 'game', 'even', 'finsish', 'br', 'br', 'peopl', 'enjoy', 'kill', 'merc', 'infiltr', 'secret', 'research', 'lab', 'locat', 'tropic', 'island', 'warn', 'near', 'cri', 'someth', 'mr', 'boll', 'scheme', 'togeth', 'along', 'legion', 'schmuck', 'feel', 'loneley', 'set', 'mr', 'boll', 'invit', 'three', 'countrymen', 'play', 'player', 'go', 'name', 'til', 'schweiger', 'udo', 'kier', 'ralf', 'moeller', 'br', 'br', 'three', 'name', 'actual', 'made', 'self', 'pretti', 'big', 'movi', 'biz', 'tale', 'goe', 'like', 'jack', 'carver', 'play', 'til', 'schweiger', 'ye', 'carver', 'german', 'hail', 'bratwurst', 'eat', 'dude', 'howev', 'find', 'til', 'act', 'movi', 'pretti', 'badass', 'peopl', 'complain', 'realli', 'stay', 'true', 'whole', 'carver', 'agenda', 'saw', 'carver', 'first', 'person', 'perspect', 'nt', 'realli', 'know', 'look', 'like', 'kick', 'br', 'br', 'howev', 'storylin', 'film', 'beyond', 'dement', 'see', 'evil', 'mad', 'scientist', 'dr', 'krieger', 'play', 'udo', 'kier', 'make', 'geneticallymutatedsoldi', 'gm', 'call', 'perform', 'topsecret', 'research', 'island', 'remind', 'spoiler', 'vancouv', 'reason', 'that', 'right', 'palm', 'tree', 'instead', 'got', 'nice', 'rich', 'lumberjackwood', 'nt', 'even', 'gone', 'far', 'start', 'cri', 'meheh', 'go', 'wan', 'na', 'stay', 'true', 'boll', 'shenanigan', 'go', 'see', 'movi', 'differ', 'disappoint', 'deliv', 'true', 'boll', 'experi', 'mean', 'suck', 'br', 'br', 'thing', 'worth', 'mention', 'would', 'impli', 'boll', 'good', 'work', 'area', 'film', 'nice', 'boat', 'fight', 'scene', 'whole', 'cromedalbino', 'gm', 'squad', 'enter', 'scene', 'everyth', 'make', 'laugh', 'movi', 'far', 'cri', 'reek', 'scheiss', 'poop', 'simpleton', 'fa', 'r', 'wan', 'na', 'take', 'wiff', 'go', 'ahead', 'btw', 'carver', 'get', 'annoy', 'sidekick', 'make', 'wan', 'na', 'shoot', 'first', 'three', 'minut', 'screen']\n"
     ]
    }
   ],
   "source": [
    "# Example of text preprocessing\n",
    "\n",
    "print(data['review'].iloc[12])\n",
    "print(preprocess(data['review'].iloc[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorizer Parameters:\n",
    "# - min_df=2: Discard words appearing in fewer than 2 documents.\n",
    "# - max_df=0.9: Discard words appearing in more than 90% of the documents.\n",
    "# - sublinear_tf=True: Use sublinear weighting for term frequency scaling.\n",
    "# - use_idf=True: Enable Inverse Document Frequency (IDF) weighting.\n",
    "\n",
    "vec = TfidfVectorizer(\n",
    "    analyzer=preprocess,\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True\n",
    ")\n",
    "\n",
    "tfidf_model = vec.fit(data['review'])\n",
    "train_vec = vec.transform(data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#save vectorizer\n",
    "vectorizer_file = 'tfidf_vectorizer.sav'\n",
    "joblib.dump(tfidf_model, open(vectorizer_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Create CountVectorizer instance with desired parameters\n",
    "count_vec = CountVectorizer(\n",
    "    analyzer=preprocess,\n",
    "    min_df=2,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "# Fit CountVectorizer on the training data\n",
    "count_model = count_vec.fit(data['review'])\n",
    "train_vec_count = count_vec.transform(data['review'])\n",
    "\n",
    "# Save the CountVectorizer model\n",
    "count_vectorizer_file = 'count_vectorizer.sav'\n",
    "joblib.dump(count_model, open(count_vectorizer_file, 'wb'))\n",
    "\n",
    "# Combine CountVectorizer and TF-IDF features\n",
    "from scipy.sparse import hstack\n",
    "combined_train_vec = hstack([train_vec_count, train_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = vec.transform(data['review'])\n",
    "train_vec_count = count_vec.transform(data['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Split data\n",
    "SEED = 4000\n",
    "X_train_count, X_test_count, y_train, y_test = train_test_split(train_vec_count, data.label, test_size=0.2, random_state=SEED)\n",
    "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(train_vec, data.label, test_size=0.2, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4921\n",
      "           1       0.87      0.85      0.86      5079\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Confusion matrix: \n",
      " [[4257  664]\n",
      " [ 749 4330]]\n",
      "Accuracy score:  0.8587\n",
      "Results with TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4946\n",
      "           1       0.90      0.89      0.90      5054\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Confusion matrix: \n",
      " [[4449  497]\n",
      " [ 557 4497]]\n",
      "Accuracy score:  0.8946\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate SVM with CountVectorizer features\n",
    "clf_svc_count = SVC(kernel='linear', random_state=39)\n",
    "clf_svc_count.fit(X_train_count, y_train)\n",
    "predictions_count = clf_svc_count.predict(X_test_count)\n",
    "print('Results with CountVectorizer:')\n",
    "print(classification_report(predictions_count, y_test))\n",
    "print('Confusion matrix: \\n', confusion_matrix(predictions_count, y_test))\n",
    "print('Accuracy score: ', accuracy_score(predictions_count, y_test))\n",
    "\n",
    "# Train and evaluate SVM with TfidfVectorizer features\n",
    "clf_svc_tfidf = SVC(kernel='linear', random_state=39)\n",
    "clf_svc_tfidf.fit(X_train_tfidf, y_train)\n",
    "predictions_tfidf = clf_svc_tfidf.predict(X_test_tfidf)\n",
    "print('Results with TfidfVectorizer:')\n",
    "print(classification_report(predictions_tfidf, y_test))\n",
    "print('Confusion matrix: \\n', confusion_matrix(predictions_tfidf, y_test))\n",
    "print('Accuracy score: ', accuracy_score(predictions_tfidf, y_test))\n",
    "\n",
    "# Save the models\n",
    "joblib.dump(clf_svc_count, open('SVM_count_model.sav', 'wb'))\n",
    "joblib.dump(clf_svc_tfidf, open('SVM_tfidf_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models\n",
    "filename_svc_count = 'SVM_count_model.sav'\n",
    "filename_svc_tfidf = 'SVM_tfidf_model.sav'\n",
    "loaded_clf_svc_count = joblib.load(open(filename_svc_count, 'rb'))\n",
    "loaded_clf_svc_tfidf = joblib.load(open(filename_svc_tfidf, 'rb'))\n",
    "\n",
    "# Load saved vectorizers\n",
    "count_vectorizer_file = 'count_vectorizer.sav'\n",
    "tfidf_vectorizer_file = 'tfidf_vectorizer.sav'\n",
    "loaded_count_vectorizer = joblib.load(open(count_vectorizer_file, 'rb'))\n",
    "loaded_tfidf_vectorizer = joblib.load(open(tfidf_vectorizer_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
