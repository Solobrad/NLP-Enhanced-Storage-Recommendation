{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>BEGIN SPOILER: Fitfully funny and memorable fo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8248</th>\n",
       "      <td>Typically Spanish production - slow-moving, bu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23301</th>\n",
       "      <td>What? - that was it? The town sheriff (John Ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47405</th>\n",
       "      <td>What Fox's fascination with dysfunctional fami...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>A lovely little film about the introduction of...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>Rating: 4 out of 10&lt;br /&gt;&lt;br /&gt;As this mini-se...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17222</th>\n",
       "      <td>Pumpkinhead was in itself a decent 80s horror ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38456</th>\n",
       "      <td>When I started watching this, I instantly noti...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>An absolutely baffling western featuring flash...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30098</th>\n",
       "      <td>I love camp movies, believe me and the usual t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "3178   BEGIN SPOILER: Fitfully funny and memorable fo...  negative\n",
       "8248   Typically Spanish production - slow-moving, bu...  positive\n",
       "23301  What? - that was it? The town sheriff (John Ag...  negative\n",
       "47405  What Fox's fascination with dysfunctional fami...  negative\n",
       "743    A lovely little film about the introduction of...  positive\n",
       "3749   Rating: 4 out of 10<br /><br />As this mini-se...  negative\n",
       "17222  Pumpkinhead was in itself a decent 80s horror ...  negative\n",
       "38456  When I started watching this, I instantly noti...  negative\n",
       "4533   An absolutely baffling western featuring flash...  negative\n",
       "30098  I love camp movies, believe me and the usual t...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB_Dataset.csv')\n",
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['sentiment'].replace(['positive', 'negative'],['1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25115</th>\n",
       "      <td>This movie was just plain bad. I can forgive l...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>I am awed by actress Bobbie Phillips and her s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11902</th>\n",
       "      <td>I guess it's Jack's great empathic ability tha...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28893</th>\n",
       "      <td>This is one of those films that's more interes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33057</th>\n",
       "      <td>I can't believe we watched this total piece of...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40078</th>\n",
       "      <td>\"Shadrach\" was not my favorite type of movie. ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36484</th>\n",
       "      <td>Without question, the worst ELVIS film ever ma...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>We bought the DVD set of \"Es war einmal das Le...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38634</th>\n",
       "      <td>'Maladolescenza' has the air of a dark fairy t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>This is yet another pseudo-intellectual \"let's...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment label\n",
       "25115  This movie was just plain bad. I can forgive l...  negative     0\n",
       "3173   I am awed by actress Bobbie Phillips and her s...  positive     1\n",
       "11902  I guess it's Jack's great empathic ability tha...  negative     0\n",
       "28893  This is one of those films that's more interes...  negative     0\n",
       "33057  I can't believe we watched this total piece of...  negative     0\n",
       "40078  \"Shadrach\" was not my favorite type of movie. ...  negative     0\n",
       "36484  Without question, the worst ELVIS film ever ma...  negative     0\n",
       "3237   We bought the DVD set of \"Es war einmal das Le...  positive     1\n",
       "38634  'Maladolescenza' has the air of a dark fairy t...  negative     0\n",
       "13610  This is yet another pseudo-intellectual \"let's...  negative     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    25000\n",
       "0    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('IMDB_Dataset_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    #1. Generating the list of words in the tweet (hastags and other punctuations removed)\n",
    "    text_blob = TextBlob(text)\n",
    "    text = ' '.join(text_blob.words)\n",
    "    \n",
    "    #2. clean the number \n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    \n",
    "    #3. lower the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #4. conver the emoji to text form\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    #5. remove punctuation \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    \n",
    "    #6. tokenize the text\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    #7. remove empty token\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    \n",
    "    #8. remove non-alphabetical token\n",
    "    text = [t for t in text if t.isalpha()]\n",
    "    \n",
    "    #9. replace the negation token\n",
    "    replacer  = AntonymReplacer()\n",
    "    text = replacer.replace_negations(text)\n",
    "    \n",
    "    #10. remove the stopwords\n",
    "    text = [i for i in text if i not in stopwords]\n",
    "    \n",
    "    #11. stem the text\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    text = [porter_stemmer.stem(w) for w in text]\n",
    "    \n",
    "    return text\n",
    "\n",
    "class AntonymReplacer(object):\n",
    "    def replace(self, word, pos=None):\n",
    "        antonyms = set()\n",
    "\n",
    "        for syn in wordnet.synsets(word, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def replace_negations(self, sent):\n",
    "        i, l = 0, len(sent)\n",
    "        words = []\n",
    "\n",
    "        while i < l:\n",
    "            word = sent[i]\n",
    "\n",
    "            if word == 'not' and i+1 < l:\n",
    "                ant = self.replace(sent[i+1])\n",
    "\n",
    "                if ant:\n",
    "                    words.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            words.append(word)\n",
    "            i += 1\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_review'] = data['review'].apply(preprocess)\n",
    "\n",
    "# Train Word2Vec models\n",
    "sentences = data['processed_review'].tolist()\n",
    "\n",
    "# CBOW model\n",
    "cbow_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, sg=0)\n",
    "# Skip Gram model\n",
    "skipgram_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, sg=1)\n",
    "\n",
    "# Save the Word2Vec models\n",
    "cbow_model.save('cbow_model.bin')\n",
    "skipgram_model.save('skipgram_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to embeddings\n",
    "def text_to_embedding(text, model):\n",
    "    embeddings = [model.wv[word] for word in text if word in model.wv]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for BiLSTM\n",
    "max_len = 100\n",
    "X_cbow = pad_sequences([text_to_embedding(text, cbow_model) for text in data['processed_review']], maxlen=max_len, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "X_skipgram = pad_sequences([text_to_embedding(text, skipgram_model) for text in data['processed_review']], maxlen=max_len, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "\n",
    "y = data['label'].astype('int')\n",
    "\n",
    "X_train_cbow, X_test_cbow, y_train, y_test = train_test_split(X_cbow, y, test_size=0.2, random_state=42)\n",
    "X_train_skipgram, X_test_skipgram, _, _ = train_test_split(X_skipgram, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "# Define BiLSTM model\n",
    "def create_bilstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(100, return_sequences=True), input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Adding dropout layer with dropout rate of 0.5\n",
    "\n",
    "    model.add(Bidirectional(LSTM(100)))\n",
    "    model.add(Dropout(0.2))  # Adding dropout layer with dropout rate of 0.5\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 263ms/step - accuracy: 0.7853 - loss: 0.4409 - val_accuracy: 0.8530 - val_loss: 0.3484\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 262ms/step - accuracy: 0.8656 - loss: 0.3215 - val_accuracy: 0.8586 - val_loss: 0.3282\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 269ms/step - accuracy: 0.8812 - loss: 0.2875 - val_accuracy: 0.8714 - val_loss: 0.3070\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 273ms/step - accuracy: 0.8900 - loss: 0.2667 - val_accuracy: 0.8733 - val_loss: 0.3090\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 282ms/step - accuracy: 0.9041 - loss: 0.2335 - val_accuracy: 0.8649 - val_loss: 0.3212\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 275ms/step - accuracy: 0.9182 - loss: 0.2096 - val_accuracy: 0.8686 - val_loss: 0.3267\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 278ms/step - accuracy: 0.9363 - loss: 0.1653 - val_accuracy: 0.8597 - val_loss: 0.3466\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 281ms/step - accuracy: 0.9499 - loss: 0.1381 - val_accuracy: 0.8670 - val_loss: 0.3929\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 279ms/step - accuracy: 0.9605 - loss: 0.1144 - val_accuracy: 0.8585 - val_loss: 0.4347\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 283ms/step - accuracy: 0.9721 - loss: 0.0822 - val_accuracy: 0.8601 - val_loss: 0.4669\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Train BiLSTM with CBOW embeddings\n",
    "bilstm_cbow_model = create_bilstm_model((max_len, 100))\n",
    "bilstm_cbow_model.fit(X_train_cbow, y_train, epochs=10, batch_size=128, validation_data=(X_test_cbow, y_test))\n",
    "# Save the models in the native Keras format\n",
    "bilstm_cbow_model.save('bilstm_cbow_model.keras')\n",
    "\n",
    "# # Train BiLSTM with Skip Gram embeddings\n",
    "# K.clear_session()\n",
    "# bilstm_skipgram_model = create_bilstm_model((max_len, 100))\n",
    "# bilstm_skipgram_model.fit(X_train_skipgram, y_train, epochs=30, batch_size=128, validation_data=(X_test_skipgram, y_test))\n",
    "# bilstm_skipgram_model.save('bilstm_skipgram_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with CBOW embeddings:\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4961\n",
      "           1       0.87      0.86      0.86      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Confusion matrix: \n",
      " [[4290  671]\n",
      " [ 728 4311]]\n",
      "Accuracy score:  0.8601\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "print('Results with CBOW embeddings:')\n",
    "y_pred_cbow = (bilstm_cbow_model.predict(X_test_cbow) > 0.5).astype('int')\n",
    "print(classification_report(y_test, y_pred_cbow))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, y_pred_cbow))\n",
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_cbow))\n",
    "\n",
    "# print('Results with Skip Gram embeddings:')\n",
    "# y_pred_skipgram = (bilstm_skipgram_model.predict(X_test_skipgram) > 0.5).astype('int')\n",
    "# print(classification_report(y_test, y_pred_skipgram))\n",
    "# print('Confusion matrix: \\n', confusion_matrix(y_test, y_pred_skipgram))\n",
    "# print('Accuracy score: ', accuracy_score(y_test, y_pred_skipgram))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models in the native Keras format\n",
    "bilstm_cbow_model.save('bilstm_cbow_model.keras')\n",
    "bilstm_skipgram_model.save('bilstm_skipgram_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# from keras.layers import Bidirectional, LSTM\n",
    "\n",
    "# # Load the models\n",
    "# loaded_bilstm_cbow_model = load_model('bilstm_cbow_model.keras')\n",
    "# loaded_bilstm_skipgram_model = load_model('bilstm_skipgram_model.keras')\n",
    "\n",
    "# # Manually recompile the models\n",
    "# loaded_bilstm_cbow_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# loaded_bilstm_skipgram_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.3\n",
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
