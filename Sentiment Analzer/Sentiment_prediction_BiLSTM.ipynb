{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29566</th>\n",
       "      <td>I would say to the foreign people who have see...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17139</th>\n",
       "      <td>I just came back from the Late-night cinema an...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>Its a very good comedy movie.Ijust liked it.I ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38645</th>\n",
       "      <td>I have been looking for this mini-series for a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24673</th>\n",
       "      <td>what a great little film, lots of good roles f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>There were a lot of dumb teenage getting sex m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36839</th>\n",
       "      <td>This seemed really similar to the CHILD'S PLAY...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26560</th>\n",
       "      <td>The idea of making a miniseries about the Berl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24217</th>\n",
       "      <td>All credit to writer/director Gilles Mimouni w...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27984</th>\n",
       "      <td>I also saw this amazingly bad piece of \"anime\"...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "29566  I would say to the foreign people who have see...  positive\n",
       "17139  I just came back from the Late-night cinema an...  positive\n",
       "18181  Its a very good comedy movie.Ijust liked it.I ...  positive\n",
       "38645  I have been looking for this mini-series for a...  positive\n",
       "24673  what a great little film, lots of good roles f...  positive\n",
       "7490   There were a lot of dumb teenage getting sex m...  positive\n",
       "36839  This seemed really similar to the CHILD'S PLAY...  negative\n",
       "26560  The idea of making a miniseries about the Berl...  negative\n",
       "24217  All credit to writer/director Gilles Mimouni w...  positive\n",
       "27984  I also saw this amazingly bad piece of \"anime\"...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB_Dataset.csv')\n",
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['sentiment'].replace(['positive', 'negative'],['1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17661</th>\n",
       "      <td>R.I.C.C.O. is the STUPIDEST film ever made. I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37412</th>\n",
       "      <td>So, it's Friday night and you want to go watch...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Tell the truth I’m a bit stun to see all these...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24232</th>\n",
       "      <td>I have the entire Weissmuller Tarzan series on...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34784</th>\n",
       "      <td>According to the blurb on the back of the DVD ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43920</th>\n",
       "      <td>Commissaire Mattei(André Bourvil) is a single ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24849</th>\n",
       "      <td>Another classic study of the effects of wealth...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46657</th>\n",
       "      <td>A year after her triumphant first special, \"My...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9620</th>\n",
       "      <td>This is perhaps the best rockumentary ever- a ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5227</th>\n",
       "      <td>Being an Austrian myself this has been a strai...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment label\n",
       "17661  R.I.C.C.O. is the STUPIDEST film ever made. I ...  negative     0\n",
       "37412  So, it's Friday night and you want to go watch...  negative     0\n",
       "352    Tell the truth I’m a bit stun to see all these...  negative     0\n",
       "24232  I have the entire Weissmuller Tarzan series on...  positive     1\n",
       "34784  According to the blurb on the back of the DVD ...  negative     0\n",
       "43920  Commissaire Mattei(André Bourvil) is a single ...  positive     1\n",
       "24849  Another classic study of the effects of wealth...  positive     1\n",
       "46657  A year after her triumphant first special, \"My...  positive     1\n",
       "9620   This is perhaps the best rockumentary ever- a ...  positive     1\n",
       "5227   Being an Austrian myself this has been a strai...  positive     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    25000\n",
       "0    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('IMDB_Dataset_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    #1. Generating the list of words in the tweet (hastags and other punctuations removed)\n",
    "    text_blob = TextBlob(text)\n",
    "    text = ' '.join(text_blob.words)\n",
    "    \n",
    "    #2. clean the number \n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    \n",
    "    #3. lower the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #4. conver the emoji to text form\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    #5. remove punctuation \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    \n",
    "    #6. tokenize the text\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    #7. remove empty token\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    \n",
    "    #8. remove non-alphabetical token\n",
    "    text = [t for t in text if t.isalpha()]\n",
    "    \n",
    "    #9. replace the negation token\n",
    "    replacer  = AntonymReplacer()\n",
    "    text = replacer.replace_negations(text)\n",
    "    \n",
    "    #10. remove the stopwords\n",
    "    text = [i for i in text if i not in stopwords]\n",
    "    \n",
    "    #11. stem the text\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    text = [porter_stemmer.stem(w) for w in text]\n",
    "    \n",
    "    return text\n",
    "\n",
    "class AntonymReplacer(object):\n",
    "    def replace(self, word, pos=None):\n",
    "        antonyms = set()\n",
    "\n",
    "        for syn in wordnet.synsets(word, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def replace_negations(self, sent):\n",
    "        i, l = 0, len(sent)\n",
    "        words = []\n",
    "\n",
    "        while i < l:\n",
    "            word = sent[i]\n",
    "\n",
    "            if word == 'not' and i+1 < l:\n",
    "                ant = self.replace(sent[i+1])\n",
    "\n",
    "                if ant:\n",
    "                    words.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            words.append(word)\n",
    "            i += 1\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the 'review' column\n",
    "\n",
    "data['processed_review'] = data['review'].apply(preprocess)\n",
    "\n",
    "# Train Word2Vec models\n",
    "sentences = data['processed_review'].tolist()\n",
    "\n",
    "# CBOW model\n",
    "cbow_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, sg=0)\n",
    "# Skip Gram model\n",
    "skipgram_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, sg=1)\n",
    "\n",
    "# Save the Word2Vec models\n",
    "cbow_model.save('Trained Model/cbow_model.bin')\n",
    "skipgram_model.save('Trained Model/skipgram_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to embeddings\n",
    "def text_to_embedding(text, model):\n",
    "    embeddings = [model.wv[word] for word in text if word in model.wv]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for BiLSTM\n",
    "max_len = 100\n",
    "X_cbow = pad_sequences([text_to_embedding(text, cbow_model) for text in data['processed_review']], maxlen=max_len, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "X_skipgram = pad_sequences([text_to_embedding(text, skipgram_model) for text in data['processed_review']], maxlen=max_len, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "\n",
    "y = data['label'].astype('int')\n",
    "\n",
    "X_train_cbow, X_test_cbow, y_train, y_test = train_test_split(X_cbow, y, test_size=0.2, random_state=42)\n",
    "X_train_skipgram, X_test_skipgram, _, _ = train_test_split(X_skipgram, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "# Define BiLSTM model\n",
    "def create_bilstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(100, return_sequences=True), input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Adding dropout layer with dropout rate of 0.5\n",
    "\n",
    "    model.add(Bidirectional(LSTM(100)))\n",
    "    model.add(Dropout(0.2))  # Adding dropout layer with dropout rate of 0.5\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 319ms/step - accuracy: 0.7928 - loss: 0.4344 - val_accuracy: 0.8509 - val_loss: 0.3535\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 309ms/step - accuracy: 0.8652 - loss: 0.3173 - val_accuracy: 0.8575 - val_loss: 0.3252\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 328ms/step - accuracy: 0.8771 - loss: 0.2973 - val_accuracy: 0.8625 - val_loss: 0.3180\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 339ms/step - accuracy: 0.8921 - loss: 0.2628 - val_accuracy: 0.8707 - val_loss: 0.3112\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 327ms/step - accuracy: 0.9050 - loss: 0.2366 - val_accuracy: 0.8730 - val_loss: 0.3035\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 314ms/step - accuracy: 0.9167 - loss: 0.2113 - val_accuracy: 0.8722 - val_loss: 0.3280\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 318ms/step - accuracy: 0.9330 - loss: 0.1727 - val_accuracy: 0.8686 - val_loss: 0.3630\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 302ms/step - accuracy: 0.9480 - loss: 0.1366 - val_accuracy: 0.8612 - val_loss: 0.4183\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 307ms/step - accuracy: 0.9608 - loss: 0.1085 - val_accuracy: 0.8649 - val_loss: 0.4386\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 297ms/step - accuracy: 0.9699 - loss: 0.0851 - val_accuracy: 0.8654 - val_loss: 0.4671\n",
      "Epoch 1/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 325ms/step - accuracy: 0.7807 - loss: 0.4567 - val_accuracy: 0.8525 - val_loss: 0.3334\n",
      "Epoch 2/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 312ms/step - accuracy: 0.8560 - loss: 0.3336 - val_accuracy: 0.8602 - val_loss: 0.3263\n",
      "Epoch 3/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 355ms/step - accuracy: 0.8622 - loss: 0.3172 - val_accuracy: 0.8588 - val_loss: 0.3225\n",
      "Epoch 4/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 390ms/step - accuracy: 0.8691 - loss: 0.3043 - val_accuracy: 0.8704 - val_loss: 0.3022\n",
      "Epoch 5/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 407ms/step - accuracy: 0.8758 - loss: 0.2949 - val_accuracy: 0.8720 - val_loss: 0.2973\n",
      "Epoch 6/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 446ms/step - accuracy: 0.8778 - loss: 0.2909 - val_accuracy: 0.8741 - val_loss: 0.3006\n",
      "Epoch 7/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 438ms/step - accuracy: 0.8839 - loss: 0.2786 - val_accuracy: 0.8730 - val_loss: 0.3067\n",
      "Epoch 8/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 439ms/step - accuracy: 0.8883 - loss: 0.2658 - val_accuracy: 0.8772 - val_loss: 0.2960\n",
      "Epoch 9/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 436ms/step - accuracy: 0.8917 - loss: 0.2600 - val_accuracy: 0.8750 - val_loss: 0.2960\n",
      "Epoch 10/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 465ms/step - accuracy: 0.8987 - loss: 0.2463 - val_accuracy: 0.8765 - val_loss: 0.2922\n",
      "Epoch 11/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 428ms/step - accuracy: 0.9029 - loss: 0.2392 - val_accuracy: 0.8769 - val_loss: 0.2966\n",
      "Epoch 12/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 542ms/step - accuracy: 0.9105 - loss: 0.2231 - val_accuracy: 0.8759 - val_loss: 0.3081\n",
      "Epoch 13/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 364ms/step - accuracy: 0.9112 - loss: 0.2153 - val_accuracy: 0.8735 - val_loss: 0.3296\n",
      "Epoch 14/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 366ms/step - accuracy: 0.9217 - loss: 0.1946 - val_accuracy: 0.8765 - val_loss: 0.3123\n",
      "Epoch 15/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 458ms/step - accuracy: 0.9242 - loss: 0.1901 - val_accuracy: 0.8740 - val_loss: 0.3334\n",
      "Epoch 16/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 458ms/step - accuracy: 0.9324 - loss: 0.1687 - val_accuracy: 0.8665 - val_loss: 0.3370\n",
      "Epoch 17/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 291ms/step - accuracy: 0.9416 - loss: 0.1549 - val_accuracy: 0.8693 - val_loss: 0.3657\n",
      "Epoch 18/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 268ms/step - accuracy: 0.9479 - loss: 0.1378 - val_accuracy: 0.8667 - val_loss: 0.3714\n",
      "Epoch 19/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 261ms/step - accuracy: 0.9537 - loss: 0.1245 - val_accuracy: 0.8665 - val_loss: 0.4011\n",
      "Epoch 20/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 257ms/step - accuracy: 0.9586 - loss: 0.1103 - val_accuracy: 0.8645 - val_loss: 0.4411\n",
      "Epoch 21/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 258ms/step - accuracy: 0.9664 - loss: 0.0928 - val_accuracy: 0.8592 - val_loss: 0.4488\n",
      "Epoch 22/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 253ms/step - accuracy: 0.9700 - loss: 0.0792 - val_accuracy: 0.8562 - val_loss: 0.5154\n",
      "Epoch 23/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 266ms/step - accuracy: 0.9729 - loss: 0.0759 - val_accuracy: 0.8589 - val_loss: 0.5375\n",
      "Epoch 24/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 329ms/step - accuracy: 0.9759 - loss: 0.0665 - val_accuracy: 0.8568 - val_loss: 0.5456\n",
      "Epoch 25/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 610ms/step - accuracy: 0.9795 - loss: 0.0559 - val_accuracy: 0.8550 - val_loss: 0.5493\n",
      "Epoch 26/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 608ms/step - accuracy: 0.9834 - loss: 0.0502 - val_accuracy: 0.8612 - val_loss: 0.5950\n",
      "Epoch 27/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 606ms/step - accuracy: 0.9854 - loss: 0.0409 - val_accuracy: 0.8613 - val_loss: 0.6688\n",
      "Epoch 28/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 604ms/step - accuracy: 0.9879 - loss: 0.0348 - val_accuracy: 0.8642 - val_loss: 0.6569\n",
      "Epoch 29/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 602ms/step - accuracy: 0.9847 - loss: 0.0408 - val_accuracy: 0.8636 - val_loss: 0.7110\n",
      "Epoch 30/30\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 2s/step - accuracy: 0.9862 - loss: 0.0384 - val_accuracy: 0.8606 - val_loss: 0.6373\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Train BiLSTM with CBOW embeddings\n",
    "bilstm_cbow_model = create_bilstm_model((max_len, 100))\n",
    "bilstm_cbow_model.fit(X_train_cbow, y_train, epochs=10, batch_size=128, validation_data=(X_test_cbow, y_test))\n",
    "# Save the models in the native Keras format\n",
    "\n",
    "# # Train BiLSTM with Skip Gram embeddings\n",
    "K.clear_session()\n",
    "bilstm_skipgram_model = create_bilstm_model((max_len, 100))\n",
    "bilstm_skipgram_model.fit(X_train_skipgram, y_train, epochs=30, batch_size=128, validation_data=(X_test_skipgram, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with CBOW embeddings:\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      4961\n",
      "           1       0.87      0.86      0.87      5039\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "Confusion matrix: \n",
      " [[4333  628]\n",
      " [ 718 4321]]\n",
      "Accuracy score:  0.8654\n",
      "Results with Skip Gram embeddings:\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4961\n",
      "           1       0.87      0.86      0.86      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Confusion matrix: \n",
      " [[4287  674]\n",
      " [ 720 4319]]\n",
      "Accuracy score:  0.8606\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "print('Results with CBOW embeddings:')\n",
    "y_pred_cbow = (bilstm_cbow_model.predict(X_test_cbow) > 0.5).astype('int')\n",
    "print(classification_report(y_test, y_pred_cbow))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, y_pred_cbow))\n",
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_cbow))\n",
    "\n",
    "print('Results with Skip Gram embeddings:')\n",
    "y_pred_skipgram = (bilstm_skipgram_model.predict(X_test_skipgram) > 0.5).astype('int')\n",
    "print(classification_report(y_test, y_pred_skipgram))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, y_pred_skipgram))\n",
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_skipgram))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models in the native Keras format\n",
    "bilstm_cbow_model.save('Trained Model/bilstm_cbow_model.keras')\n",
    "bilstm_skipgram_model.save('Trained Model/bilstm_skipgram_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# from keras.layers import Bidirectional, LSTM\n",
    "\n",
    "# # Load the models\n",
    "# loaded_bilstm_cbow_model = load_model('bilstm_cbow_model.keras')\n",
    "# loaded_bilstm_skipgram_model = load_model('bilstm_skipgram_model.keras')\n",
    "\n",
    "# # Manually recompile the models\n",
    "# loaded_bilstm_cbow_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# loaded_bilstm_skipgram_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
